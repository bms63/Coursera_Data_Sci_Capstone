install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
data(concrete)
library(caret)
install.packages("caret")
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
View(training)
plot(concrete$CompressiveStrength)
str(training)
plot(concrete$CompressiveStrength, factor(x=Age))
plot(concrete$CompressiveStrength, factor(x=concrete$Age))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProcess(training)
preProc <- preProcess(training)
View(preProc)
princomp(preProc)
class(preProc)
princomp(training)
View(training)
training <- training[-1,]
training
View(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,-1]
View(training)
princomp(training)
princomp(training, scale=TRUE, center=TRUE)
str(raining)
str(training)
str(preProcess)
preProc <- preProcess(training, method="pca")
preProc
preProc <- preProcess(training, method="pca", thresh=.9)
preProc
argh <-training[,grep("^[IL]", names(training), value=TRUE)]
View(argh)
argh <-training[,grep("[IL]", names(training), value=TRUE)]
Vuew(argh)
View(argh)
argh <-training[,grep("^[IL_]", names(training), value=TRUE)]
argh <-training[,grep("^[IL_]", names(training), fixed=TRUE)]
argh <-training[,grep("^[IL_]", names(training), fixed=TRUE, value=TRUE)]
View(argh)
argh <-training[,grep("^[IL_]", names(training), value=TRUE)]
argh <- argh[,-(1:3)]
argh <- argh[,-(14:18)]
princomp(argh)
preProcess(argh, method="pca", thresh=.9)
preProcess(argh, method="pca")
getwd()
setwd("C:/Users/Clover/Desktop")
list.files()
setwd("C:/Users/Clover/")
setwd("C:/Users/Clover/")
list.files()
setwd("C:/Users/Clover/Desktop")
list.files()
list.dirs()
setwd("C:/Users/Clover/Downloads")
list.files()
setwd("C:/Users/Clover/Downloads")
list.files*
list.files()
data <- read.csv("pml-training.csv")
setwd("C:/Users/Clover/Downloads")
data <- read.csv("pml-training.csv")
data <- read.csv("pml-training.csv")
list.files()
data <- read.csv("pml-training.csv")
list.files()
data <- read.csv("pml-training.csv")
data <- read.csv("pml-training.csv")
data <- read.csv("pml-training.csv")
list.files()
getwd()
setwd("/Users/benStraub/Desktop/580_consulting/")
setwd("/Users/benStraub/Desktop/580_consulting/")
setwd("/Users/benStraub/Desktop/580_consulting/")
setwd("/Users/Clover/Desktop/580_consulting/")
setwd("C:\Users\Clover\Music\Documents\GitHub\580_consulting")
setwd("C:/Users/Clover/Music/Documents/GitHub/580_consulting")
data <- read.csv("pml-training.csv")
list.files()
setwd("C:/Users/Clover/Music/Documents/GitHub/580_consulting")
list.files()
data <- read.csv("pmltraining.csv")
setwd("C:/Users/Clover/Music/Documents/GitHub/580_consulting")
data <- read.csv("pmltraining.csv")
View(data)
data <- read.csv("pmltraining.csv")
setwd("C:/Users/Clover/Music/Documents/GitHub/580_consulting")
data <- read.csv("pmltraining.csv")
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling);library(caret)
str(data)
names(data)
sapply(data, function(x)all(is.na(x)))
tail(names(data))
na_count <-sapply(x, function(y) sum(length(which(is.na(y)))))
na_count <-sapply(data, function(y) sum(length(which(is.na(y)))))
class(na_count)
na_count
final <- data[, colMeans(is.na(data)) <= .15]
final_data <- data[, colMeans(is.na(data)) <= .15]
View(final_data)
final_data <- data[, colMeans(is.na(data)) <= .5]
dim(final_data)
dim(data)
final_data <- data[, colMeans(is.na(data)) <= .9]
dim(final_data)
19216/19622
str(final_data)
data <- read.csv("pmltraining.csv",na.strings=c('#DIV/0', '', 'NA'),stringsAsFactors = F)
dim(data)
sapply(data, function(x)all(is.na(x)))
na_count <-sapply(data, function(y) sum(length(which(is.na(y)))))
na_count
final_data <- data[, colMeans(is.na(data)) <= .95]
View(final_data)
dim(final_data)
final_data <- data[, colMeans(is.na(data)) <= .5]
View(final_data)
dim(final_data)
str(final_data)
inTrain <- createDataPartition(y = final_data$classe, p=.75,list=FALSE)
dim(inTrain)
training <- final_data[inTrain,]
testing <- final_data[-inTrain,]
dim(training)
dim(testing)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbmFit1 <- train(classe ~ ., data = training,
method = "rpart",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(AppliedPredictiveModeling);library(caret);library(e1071)
install.packages("e1071")
library(e1071)
rpartFit1 <- train(classe ~ ., data = training,
method = "rpart",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(datasets)
library(ggplot2)
jpeg(paste0("iris.jpg"))
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
irisCluster$tot.withinss
irisCluster$withinss
set.seed(20)
irisCluster2 <- kmeans(iris[, 3:4], 2, nstart = 20)
irisCluster3 <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster4 <- kmeans(iris[, 3:4], 4, nstart = 20)
irisCluster2$withinss
irisCluster3$withinss
irisCluster4$withinss
str(Iris)
library(datasets)
data("iris")
str(iris)
table(iris$Species)
irisCluster2$centers
irisCluster3$centers
irisCluster4$centers
irisCluster2$centers$Petal.Length
class(irisCluster2$centers)
str(irisCluster2$centers)
irisCluster2$centers[1]
irisCluster2$centers[1,]
irisCluster2$centers[,1]
irisCluster2$centers[,1]
plot(irisCluster2$cluster <- as.factor(irisCluster2$cluster)
jpeg(paste0("iris2.jpg"))
ircl2 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster2$cluster)) + geom_point() + geom_point(aes(x=irisCluster2$centers[,1],y=irisCluster2$centers[1,], color=red))
ircl2 + ggtitle("K=2"))
plot(irisCluster2$centers)
x11()
plot(irisCluster2$centers)
irisCluster22 <- kmeans(iris[, 3:4], 2, nstart = 20)
irisCluster21 <- kmeans(iris[, 3:4], 2, nstart = 10)
irisCluster32 <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster31 <- kmeans(iris[, 3:4], 3, nstart = 10)
irisCluster42 <- kmeans(iris[, 3:4], 4, nstart = 20)
irisCluster41 <- kmeans(iris[, 3:4], 4, nstart = 10)
irisCluster22$cluster <- as.factor(irisCluster22$cluster)
jpeg(paste0("iris22.jpg"))
ircl22 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster22$cluster)) + geom_point()
ircl22 + ggtitle("K=2, nstart=20")
irisCluster21$cluster <- as.factor(irisCluster21$cluster)
jpeg(paste0("iris21.jpg"))
ircl21 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster21$cluster)) + geom_point()
ircl21 + ggtitle("K=2, nstart=10")
irisCluster32$cluster <- as.factor(irisCluster32$cluster)
jpeg(paste0("iris32.jpg"))
ircl32 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster23$cluster)) + geom_point()
ircl32 + ggtitle("K=3, nstart=20")
irisCluster31$cluster <- as.factor(irisCluster31$cluster)
irisCluster32$cluster <- as.factor(irisCluster32$cluster)
jpeg(paste0("iris32.jpg"))
ircl32 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster32$cluster)) + geom_point()
ircl32 + ggtitle("K=3, nstart=20")
irisCluster31$cluster <- as.factor(irisCluster31$cluster)
jpeg(paste0("iris31.jpg"))
ircl31 <- ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster13$cluster)) + geom_point()
ircl31 + ggtitle("K=3, nstart=10")
irisCluster42$cluster <- as.factor(irisCluster42$cluster)
irisCluster22$totss
irisCluster21$totss
irisCluster32$totss
irisCluster2$totss
irisCluster42$totss
irisCluster32$tot.withinss
irisCluster21$tot.withinss
irisCluster22$tot.withinss
irisCluster21$tot.withinss
irisCluster31$tot.withinss
irisCluster32$tot.withinss
irisCluster41$tot.withinss
irisCluster42$tot.withinss
totTable <- cbind(irisCluster22$tot.withinss,
irisCluster21$tot.withinss,
irisCluster31$tot.withinss,
irisCluster32$tot.withinss,
irisCluster41$tot.withinss,
irisCluster42$tot.withinss)
totTable
class(totTable)
totTable <- colnames(c("K=2,nstart=20","K=2,nstart=10","K=3,nstart=20","K=3,nstart=10","K=4,nstart=20","K=4,nstart=10"))
totTable
totTable <- cbind(irisCluster22$tot.withinss,
irisCluster21$tot.withinss,irisCluster32$tot.withinss,
irisCluster31$tot.withinss,irisCluster42$tot.withinss,
irisCluster41$tot.withinss)
totTable
totTable <- colnames(c("K=2,nstart=20","K=2,nstart=10","K=3,nstart=20","K=3,nstart=10","K=4,nstart=20","K=4,nstart=10"))
totTable
colnames(totTable) <- c("K=2,nstart=20","K=2,nstart=10","K=3,nstart=20","K=3,nstart=10","K=4,nstart=20","K=4,nstart=10")
str(totTable)
i
totTable <- cbind(irisCluster22$tot.withinss,
irisCluster21$tot.withinss,irisCluster32$tot.withinss,
irisCluster31$tot.withinss,irisCluster42$tot.withinss,
irisCluster41$tot.withinss)
str(totTable)
varnames <- c("K=2,nstart=20","K=2,nstart=10","K=3,nstart=20","K=3,nstart=10","K=4,nstart=20","K=4,nstart=10")
totTable <- rbind(varnames,totTable)
totTable
View(totTable)
totwithinss <- cbind(irisCluster22$tot.withinss,
irisCluster21$tot.withinss,irisCluster32$tot.withinss,
irisCluster31$tot.withinss,irisCluster42$tot.withinss,
irisCluster41$tot.withinss)
varnames <- c("K=2,nstart=20","K=2,nstart=10","K=3,nstart=20","K=3,nstart=10","K=4,nstart=20","K=4,nstart=10")
totTable <- rbind(varnames,totwithinss)
totTable
View(totTable)
install.packages("ISLR")
set.seed(2)
X <- seq(-4*pi,4*pi,0.01)
length(X)
y <- cos(X) + sin(X)
data <- cbind(X,y)
View(data)
trainIndex <- createDataPartition(y=data$y, times = 1, p = 0.5, list = FALSE)
library(caret)
set.seed(2)
X <- seq(-4*pi,4*pi,0.01)
y <- cos(X) + sin(X)
data <- cbind(X,y)
trainIndex <- createDataPartition(y=data$y, times = 1, p = 0.5, list = FALSE)
data <- as.data.frame(cbind(X,y))
trainIndex <- createDataPartition(y=data$y, times = 1, p = 0.5, list = FALSE)
dataTrain <- data[ trainIndex,]
dataTest  <- data[-trainIndex,]
dim(dataTrain)
dim(dtaTest)
trainIndex <- createDataPartition(y=data$y, times = 1, p = 0.7, list = FALSE)
dataTrain <- data[ trainIndex,]
dataTest  <- data[-trainIndex,]
dim(dataTrain)
dim(dataTest)
trainIndex <- createDataPartition(y=data$y, times = 1, p = 0.8, list = FALSE)
dataTrain <- data[ trainIndex,]
dataTest  <- data[-trainIndex,]
dim(dataTrain)
dim(dataTest)
install.packages("matrixcalc")
install.packages("KRLS")
install.packages("kableExtra")
install.packages("broom")
getwd()
getwd()
setwd("C:/Users/Clover/")
list.files()
setwd("C:/Users/Clover/Desktop")
list.files*
list.files*
list.files()
setwd("C:/Users/Clover/Desktop/DSS_Capstone")
setwd("C:/Users/Clover/Desktop/DSS_Capstone/final")
list.files()
setwd("C:/Users/Clover/Desktop/DSS_Capstone/final/en_US")
en_US_blogs <- read.table(en_US.blogs.txt)
setwd("C:/Users/Clover/Desktop/DSS_Capstone/final/en_US")
en_US_blogs <- read.table(en_US.blogs.txt)
en_US_blogs <- read.table("en_US.blogs.txt")
en_US_blogs <- read.table("en_US.blogs.txt", header=FALSE, sep="")
en_US_blogs <- read.table("en_US.blogs.txt", header=FALSE, sep="",blank.lines.skip = TRUE, text)
en_US_blogs <- read.table("en_US.blogs.txt", header=FALSE, sep="", na.strings=TRUE, blank.lines.skip = TRUE, text)
en_US_blogs <- read.table("en_US.blogs.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE)
en_US_blogs <- read.table("en_US.blogs.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE, fill=TRUE)
dim(en_US_blogs)
list.files()
en_US_blogs <- read.table("en_US.twitter.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE, fill=TRUE)
dim(en_US_blogs)
en_US_news <- read.table("en_US.news.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE, fill=TRUE)
dim(en_US_news)
hate = grep('hate', en_US_twitter)
en_US_twitter <- read.table("en_US.twitter.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE, fill=TRUE)
hate = grep('hate', en_US_twitter)
love = grep('love', en_US_twitter)
length(love)/length(hate)
hate
love
en_US_twitter <- read.table("en_US.twitter.txt", header=FALSE, sep="", na.strings=TRUE,
blank.lines.skip = TRUE, fill=FALSE)
View(en_US_twitter)
hate = agrep('hate', en_US_twitter)
hate
install.packages('tm')
library(tm)
mydata.corpus <- Corpus(VectorSource(en_US.twitter.txt))
vs <- VectorSource(en_US_twitter)
vs <- VectorSource(en_US_twitter.txt)
result <- readPlain(elem, "en", "id1")
